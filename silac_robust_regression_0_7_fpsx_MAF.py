############################################                                         ## SILAC Peptide Ratio Calculator          ## by Xiaoyan Guan and Michael A. Freitas  ## The Ohio State University               ##                                         #############################################Define mass of the isotopic labelsC12=12.00000 # Carbon 12 C13=13.003355 # Carbon 13C13Shift = C13-C12 # Difference in Carbon MassN14=14.003074 # Nitrogen 14N15=15.000109 # Nitrogen 15N15Shift=N15-N14 # Difference in Nitrongen Masslabel_default=6*C13Shift + 2*N15Shift # Default Label 13C6 15N2 + 8DaH=1.007825 # Hydrogen MassElec=0.00054858 # Electron Massproton=H-Elec # Proton Mass#Default parameters        DEFAULTTOL = 0.01 # Mass accuracyDEFAULTTHRESHOLD = 100000  # Signal rejection ThresholdSCANWINDOW = 0.5 # Sliding time windowSTARTSCAN = 0 # Start ScanENDSCAN = 1000000 # End ScanSTARTMASS = 350 # Minimum massENDMASS = 2000  # Maximum massMAXISO = 4      # Maximum number of isotopesMAXCHARGE = 4   # Maximum number of chargesNORMCHARGE = [3] # Normalization charge# Python importsimport osimport csvimport sysimport reimport mathimport numpyimport optparsefrom mm_mzxml_lxml import *from math import sqrtimport matplotlib.pyplotimport matplotlibdef saveplot_ratios(X, Y, filename):    """    Create plots for light and heavy abundances of all peptides    """        # creates pyplot figure object    matplotlib.pyplot.figure()        #plot data    matplotlib.pyplot.scatter(X, Y, s=4,color="black",lw = 0, label="L vs H abund")    #add in labels and title    matplotlib.pyplot.xlabel("Light Abundance")    matplotlib.pyplot.ylabel("Heavy Abundance")    matplotlib.pyplot.suptitle(filename)    #save figure to png    matplotlib.pyplot.savefig(str(filename) + ".pdf")    matplotlib.pyplot.clf()def saveplot_ratios_w_regs(X, Y, filename, slope1, intercept1, slope2, intercept2, mnr = -1, mnrwa = -1, size = 4 ):    """    Summary          Create scatter plots for the light and heavy abundance of peptide peaks with regression lines    Usage        saveplot_ratios_w_regs(X, Y, filename, slope1, intercept1, slope2, intercept2, mnr = -1, mnrwa = -1, size = 4 ):    Returns a scatter plot for light:heavy abundance of all peptides with normalization factors or light:heavy abundance of    a single peptide with peptide ratio    """      # creates pyplot figure object        matplotlib.pyplot.figure()        #plot data    matplotlib.pyplot.scatter(X, Y, s=size,color="black",lw = 0, label="L vs H abund")    #set axes limits and save figure to png    txmin,txmax = matplotlib.pyplot.xlim()    tymin,tymax = matplotlib.pyplot.ylim()    if txmax > tymax:        tymax = txmax    else:        txmax = tymax    matplotlib.pyplot.xlim(0.0,txmax)    matplotlib.pyplot.ylim(0.0,tymax)    Xreg = [0.0,txmax]    #Set the location of the regression lines    miny1=float(intercept1)    maxy1=float(txmax) * float(slope1) + float(intercept1)    Yreg1 = [miny1,maxy1]    miny2=float(intercept2)    maxy2=float(txmax) * float(slope2) + float(intercept2)    Yreg2 = [miny2,maxy2]        #Draw the robust linear regression and linear regression lines    matplotlib.pyplot.plot(Xreg, Yreg1,label="RLR regression="+ str("%.2f" % slope1), color="black", ls="solid")    matplotlib.pyplot.plot(Xreg, Yreg2,label="LR regression="+ str("%.2f" % slope2), color="black", ls="dashed")    # Draw the regression lines by the median and abundance weighted median ratio if applicable    if mnr != -1:        miny3 = 0.0        maxy3= float(txmax) * float(mnr)        Yreg3 = [miny3,maxy3]             matplotlib.pyplot.plot(Xreg, Yreg3,label="Median ratio="+ str("%.2f" % mnr), color="black", ls="dashdot")    if mnrwa != -1:        miny4 = 0.0        maxy4= float(txmax) * float(mnrwa)        Yreg4 = [miny4,maxy4]             matplotlib.pyplot.plot(Xreg, Yreg4,label="Weighted Median ratio="+ str("%.2f" % mnrwa), color="black", ls="dotted")          #add in legend, labels and title    matplotlib.pyplot.xlabel("Light Abundance")    matplotlib.pyplot.ylabel("Heavy Abundance")    matplotlib.pyplot.suptitle(filename)    matplotlib.pyplot.legend()     #Draw the line y=x as a reference for a unity ratio    matplotlib.pyplot.plot((0,txmax), (0,tymax), color="red", ls="dotted")    #Save plot in pdf        matplotlib.pyplot.savefig(str(filename) + ".pdf")    matplotlib.pyplot.clf()def saveplot_norm_ratios(X, Y, Z, filename):    """    Summary        Create a heatmap of the SILAC ratios     """      # creates pyplot figure object    matplotlib.pyplot.figure()    for i in range(0,len(Z)):        Z[i] = math.log(Z[i],2)       #plot data    matplotlib.pyplot.scatter(X, Y, c=Z, s=4, lw = 0, label="log2 ratio", cmap=matplotlib.cm.RdYlGn_r)    cb = matplotlib.pyplot.colorbar()    cb.set_label('log2 ratio')    matplotlib.pyplot.legend()            #add in labels and title    matplotlib.pyplot.xlabel("Retention Time")    matplotlib.pyplot.ylabel("Light Mass")    matplotlib.pyplot.suptitle(filename)    # save plot in pdf    matplotlib.pyplot.savefig(str(filename) + ".pdf")    matplotlib.pyplot.clf()    # Define linear regression	def linreg(X, Y):    """    Summary        Linear regression of y = ax + b    Usage        real, real, real = linreg(list, list)    Returns coefficients to the regression line "y=ax+b" from x[] and y[], and R^2 Value    """        if len(X) != len(Y):  raise ValueError, 'unequal length'       N = len(X)    Sx = Sy = Sxx = Syy = Sxy = 0.0       for x, y in map(None, X, Y):        Sx = Sx + x        Sy = Sy + y        Sxx = Sxx + x*x        Syy = Syy + y*y        Sxy = Sxy + x*y           det = Sxx * N - Sx * Sx        a, b = (Sxy * N - Sy * Sx)/det, (Sxx * Sy - Sx * Sxy)/det       meanerror = residual = 0.0        for x, y in map(None, X, Y):        meanerror = meanerror + (y - Sy/N)**2        residual = residual + (y - a * x - b)**2            RR = 1 - residual/meanerror    ss = residual / (N-2)    StdDev_a, StdDev_b = sqrt(ss * N / det), sqrt(ss * Sxx / det)    return a, b, RR, ss, StdDev_a, StdDev_b, N# Define robust linear regression	def ktrreg(X, Y):    """    Summary        Kendall Thiel, Robust Linear regression of y = ax + b    Usage        real, real, list = ktrreg(list, list)         Returns coefficients to the regression line "y=ax+b" from x[] and y[], and median ratios    """       if len(X) > 0 and len(Y) > 0 and len(X) == len(Y):        # Create lists        cratios = []        iratios = []        results = []        # Calculate the slope using the complete version of the Kendall Theil        if len(X) < 10000:           for i in range(0, len(X)):                for j in range(i+1, len(X)):                    if X[j] == X[i] or Y[j] == Y[i]:                        continue                    else:                         cratios.append(math.fabs(float(Y[j]-Y[i])/float(X[j]-X[i])))        # Calculate the slope using the incomplete version of the Kendall Theil, Thiel's Method        halflen = len(X)/2        for i in range(0,halflen):            if X[halflen+i] == X[i] or Y[halflen+i] == Y[i]:                continue            else:                iratios.append(math.fabs(float(Y[halflen+i]-Y[i])/float(X[halflen+i]-X[i])))               # Sort lists        cratios.sort()        iratios.sort()                X.sort()        Y.sort()               # Calculate slope by the Thiel's method and its corresponding intercept        ti_slope = iratios[len(iratios)/2]                Xmed = X[len(X)/2]        Ymed = Y[len(Y)/2]        ti_intercept = Ymed - ti_slope * Xmed        # Calculate standard deviation of the slope and intercept        N = len(X)        Sx = Sy = Sxx = Syy = Sxy = 0.0        for x, y in map(None, X, Y):            Sx = Sx + x            Sy = Sy + y            Sxx = Sxx + x*x            Syy = Syy + y*y            Sxy = Sxy + x*y        det = Sxx * N - Sx * Sx        a, b = ti_slope, ti_intercept        meanerror = residual = 0.0        for x, y in map(None, X, Y):            meanerror = meanerror + (y - Sy/N)**2            residual = residual + (y - a * x - b)**2        RR = 1 - residual/meanerror        ss = residual / (N-2)        StdDev_a, StdDev_b = sqrt(ss * N / det), sqrt(ss * Sxx / det)        # Append results to lists        results.append(ti_slope)        results.append(ti_intercept)        results.append(iratios)        results.append(StdDev_a)        results.append(StdDev_b)        return results        else:        return -1# Define median         def listmed(X, Y):    """    Summary        Returns median ratio    """    if len(X) > 0 and len(Y) > 0 and len(X) == len(Y):        ratio = []        for i in range(0, len(X)):            ratio.append ( float(Y[i]/X[i]))        ratio.sort()        medratio =ratio[len(ratio)/2]        return medratio           else:        return -1def getRetTime(rettime):    pattern = re.compile(r'PT(\d*.\d*)S')    time = pattern.search(rettime).groups()    return float(time[0])def updateStdOut(string):    sys.stdout.write("%s\r" % (string,))    sys.stdout.flush()def main():    print """-----------------------------------------------------SILAC Peptide Ratio Calculator          by Xiaoyan Guan and Michael A. Freitas The Ohio State University  -----------------------------------------------------    """      # Import Psyco if available    try:        import psyco        psyco.full()    except ImportError:        print "\n** Warning: psyco import failed. Running without psyco optimization **\n"        pass          # Command Line parsing    parser = optparse.OptionParser()    parser.add_option("-i", "--input", action="store", dest="data_file", \                      help="input FILE", metavar="FILE")    parser.add_option("-x", "--normfile", action="store", dest="norm_file", \                      help="input normalization FILE", metavar="FILE")    parser.add_option("-m", "--mass", action="append", dest="target_mass", \                      type="float", help="set the monoisotopic M+H mass to search", \                      metavar="FILE")    parser.add_option("-t", "--tol", action="store", dest="tol", type="float",                           help="set tolerance")    parser.add_option("-y", "--threshold", action="store", dest="threshold", type="float",                          help="set threshold")    parser.add_option("-f", "--norm_ratio_cutoff", action="store", dest="norm_ratio_cutoff", type="float",                          help="set norm_ratio_cutoff")                                  parser.add_option("-u", "--smass", action="store", dest="start_mass",type="float",                          help="set start mass")    parser.add_option("-v", "--emass", action="store", dest="end_mass",type="float",                           help="set end mass")    parser.add_option("-j", "--sscan", action="store", dest="start_scan",type="float",                        help="set start scan")    parser.add_option("-k", "--escan", action="store", dest="end_scan",type="float",                            help="set end scan")    parser.add_option("-w", "--wind", action="store", dest="scan_window", type="float",                            help="set scan window")    parser.add_option("-d", "--debug", action="store_true", dest="debug",                            help="set debug")    parser.add_option("-n", "--labeln", action="append", dest="num_labels", type="int",                            help="set number of labels")    parser.add_option("-c", "--labelnnorm", action="store", dest="num_labels_norm", type="int",                            help="set number of labels for normalization")    parser.add_option("-l", "--labelm", action="store", dest="label_mass", type="float",                            help="set mass of label")    parser.add_option("-s", "--normreload", action="store", dest="norm_reload", type="int",                            help="Skip normalization if norm file is present")    parser.add_option("-p", "--peptideseq", action="store", dest="peptide_seq", type="str",                            help="describe the peptide sequence")    (options, args) = parser.parse_args()    if not options.target_mass and options.data_file:        print "please input zero charge target mass"        sys.exit(0)    else:         data_file = options.data_file            # Look for the normalization file of the same data file, if applicable, skip the normalization            if options.norm_file:         try:            norm_file = csv.reader(open(options.norm_file, 'r'))            header = norm_file.next()            norm_file_factors = norm_file.next()            print header            print norm_file_factors            for row in norm_file:                print ', '.join(row)            skip_norm = 1          except:            print "Normalization file not found"            sys.exit(0)    else:        skip_norm = 0    if options.norm_reload:         norm_reload = options.norm_reload    else:        norm_reload = 0    if options.peptide_seq:         peptide_seq = options.peptide_seq    else:        peptide_seq = XXXXXX            if options.tol:         tol = options.tol / 2.0    else:        tol = DEFAULTTOL / 2.0    if not options.num_labels:        print "Warning no number of labels specified.  Setting to 1 for all target masses"        options.num_labels = [1]*len(options.target_mass)    if len(options.num_labels) != len(options.target_mass):        print "Mismatch in number of target masses and label numbers"        sys.exit(0)            # Use peptide with one isotopic label for normalization    if not options.num_labels_norm:         options.num_labels_norm = 1     if not options.label_mass:         options.label_mass = label_default     if options.threshold:         threshold = options.threshold        else:        threshold = DEFAULTTHRESHOLD            # Set the log2 filter of SILAC ratio for normalization    if options.norm_ratio_cutoff:         norm_ratio_cutoff = options.norm_ratio_cutoff        else:        norm_ratio_cutoff = 2.0            if options.start_mass:         start_mass = options.start_mass    else:        start_mass = STARTMASS    if options.start_scan:         start_scan = options.start_scan    else:        start_scan = STARTSCAN        if options.end_mass:         end_mass = options.end_mass    else:        end_mass = ENDMASS                        if options.end_scan:         end_scan = options.end_scan    else:        end_scan = ENDSCAN                       if options.scan_window:         rettime_tol = options.scan_window           else:        rettime_tol = SCANWINDOW            if options.debug:        DEBUG = True    else:        DEBUG = False           if options.debug:        debug = True    maxcharge = MAXCHARGE    maxiso = MAXISO    #extract basename    basename = os.path.splitext(os.path.basename(data_file))       print "Starting Analysis of " + str(data_file)    # Look for the normalization file of the same data file, if applicable, skip the normalization    if norm_reload != 0:          try:                         norm_file = csv.reader(open(basename[0]+"_norm_factors.csv", 'r'))            header = norm_file.next()            norm_file_factors = norm_file.next()            print header            print norm_file_factors            for row in norm_file:                print ', '.join(row)            skip_norm = 1                except:            print "Normalization file not found Proceeding with Normalization"    # Print a list of the mass and number of isotopic label of the target peptides    for m in range(0,len(options.target_mass)):        print "   " + str(m+1)+": target = " + str(options.target_mass[m]) + " # labels = " + str(options.num_labels[m])    # Extract data file    mzxml = mzXMLDoc();    mzxml.getDocument(data_file)    # Create lists    peaks = []    mass = []    abund = []    test_abund = []    rtime = []    scan_num = []    num_peaks = []    results = []    print "Finding Normalization Ratios (Using first num_labels argument for Normalization)"      # Read in scans and parse data     kt_norm_ratios = []    kt_slope = 0    kt_intercept = 0    # Create lists of heavy/light mass and abundance for all peptides    all_norm_light_masses = []    all_norm_heavy_masses = []    all_norm_light_abund = []    all_norm_heavy_abund = []    all_norm_retention = []   # Create lists of heavy/light mass and abundance for peptides selected to generate normalization factor     norm_ratios = []    norm_ratios_wt_abund = []    norm_light_masses = []    norm_heavy_masses = []    norm_light_abund = []    norm_heavy_abund = []    norm_charge = []    norm_retention = []        # Create lists of heavy/light mass and abundance for each target peptide     light_masses = []    light_abund = []    heavy_masses = []    heavy_abund = []      label = options.label_mass * options.num_labels_norm#############################################   Calculate the normalization factor     #############################################    # Scan through all peaks    for scan in mzxml.scans:        scan_num.append( scan.get('num') )        if int(start_scan) > int(scan.get('num')):            continue        elif int(end_scan) < int(scan.get('num')):            continue         elif 1 == int(scan.get('msLevel')):             peaks = mzxml.getPeaks(scan)            ret_time = getRetTime(scan.get('retentionTime'))            # Select a light peak with the appropriate mass and threshold            for i in range(0,len(peaks)):               if peaks[i][0] <= start_mass:                   continue               elif peaks[i][0] >= end_mass:                   continue               elif peaks[i][1] <= threshold:                   continue               # Find the matched pairs for all peptides               for j in range(i+1, len(peaks)):                   if peaks[j][0] >= end_mass:                       continue                   elif peaks[j][1] <= threshold:                       continue                   elif math.fabs(peaks[j][0] - peaks[i][0]) > label:                       break                   else:                       for c in range(1,maxcharge):                            if math.fabs((peaks[i][0] + label/c) - peaks[j][0]) < tol:                                 all_norm_light_masses.append(peaks[i][0])                                 all_norm_heavy_masses.append(peaks[j][0])                                 all_norm_light_abund.append(peaks[i][1])                                  all_norm_heavy_abund.append(peaks[j][1])                                  all_norm_retention.append(ret_time)                                            for charge in NORMCHARGE:                            normc = int(charge)                             if math.fabs((peaks[i][0] + label/normc) - peaks[j][0]) < tol:                                 tmp_norm_ratio = peaks[j][1]/peaks[i][1]                                                   if tmp_norm_ratio < norm_ratio_cutoff and tmp_norm_ratio > 1/norm_ratio_cutoff:                                    norm_light_masses.append(peaks[i][0])                                     norm_heavy_masses.append(peaks[j][0])                                     norm_light_abund.append(peaks[i][1])                                      norm_heavy_abund.append(peaks[j][1])                                      norm_retention.append(ret_time)                                          norm_ratios.append(peaks[j][1]/peaks[i][1])                                    norm_charge.append(normc)                                                        if skip_norm != 1:          if len(norm_ratios) > 0:            print "Calculating Normalization Factors ..."                        # Save the list of light/heavy mass and abundance of the matched pairs in excel worksheet            filename = basename[0]+"_all_light_heavy_abund.csv"               FILE = open(filename,'w')            FILE.write("Retention Time,charge,Light Mass, Light Abundance, Heavy Mass, Heavy Abundance, Ratio\n")                             for i in range(0, len(norm_light_abund)): 		                FILE.write(str(norm_retention[i])+", "+ str(norm_charge[i]) + "," + str(norm_light_masses[i])+", "+ \                       str(norm_light_abund[i])+", "+str(norm_heavy_masses[i])+", "+ \                       str(norm_heavy_abund[i])+", "+ str(norm_ratios[i])+"\n")            FILE.close()                        # Plot the heatmap for ratios of all matched pairs             plot_filename = basename[0]+"_normalization_heat_map"            saveplot_norm_ratios(norm_retention[:],norm_light_masses[:],norm_ratios[:],plot_filename)                        # Estimate the normalization factor by the median ratio and abundance weighted median ratio             maxlightabund = max(norm_light_abund)            maxheavyabund = max(norm_heavy_abund)            maxabund = max ([maxlightabund,maxheavyabund])                              wf_bins = len(norm_light_abund)/10                      wf_dist = [0.0]*(wf_bins+1)                       for i in range(0,len(norm_ratios)):                           wf = int(wf_bins*(norm_light_abund[i] / maxabund))+1  # Add additional weight to ratios generated from highly abundant peptides                norm_ratios_wt_abund.extend([norm_ratios[i]]  *wf)                wf_dist[wf-1] = wf_dist[wf-1] + 1.0                   norm_ratios_wt_abund.sort()                           norm_ratios.sort()                      med_norm_ratio = norm_ratios[len(norm_ratios)/2]            med_norm_ratios_wt_abund = norm_ratios_wt_abund[len(norm_ratios_wt_abund)/2]            # Calculate the normalization factor by robust linear regression             ktdata = ktrreg(norm_light_abund[:],norm_heavy_abund[:])            filename = basename[0]+"_ti_norm_ratios_tmp.csv"               FILE = open(filename,'w')            NUMDATAPTS = 1000000                                           listlen = len(ktdata[2])            if listlen > NUMDATAPTS:                                           for i in range(0,NUMDATAPTS):                    index = int(listlen / float(NUMDATAPTS) * i)                                FILE.write(str(ktdata[2][index])+"\n")            else:                for i in range(0,listlen):                                    FILE.write(str(ktdata[2][i])+"\n")            FILE.close()            # Calculate the normalization factor by linear regression                             regresult = linreg(norm_light_abund[:],norm_heavy_abund[:])            # Calculate the normalization factor by the average ratio            avg_norm_ratio = sum(norm_ratios)/len(norm_ratios)                               # Create a list of normalization factors estimated by the log2 filtered Robust linear regression slope, Linear regression slope, Median ratio and Abundance weighted median ratio            filename = basename[0]+"_norm_factors.csv"            FILE = open(filename,'w')            FILE.write("file, Label Mass, Num of Labels, Number of ratios, RLR Slope, RLR Intercept, LR Slope, LR Intercept, Median Ratio, Abundance Weighted Median Ratio, Average Ratio" +"\n")            FILE.write(basename[0]+","+str(options.label_mass)+","+str(options.num_labels_norm)+","+ \                       str(len(norm_ratios))+","+ \                       str(ktdata[0])+","+str(ktdata[1])+","+str(regresult[0])+","+ \                       str(regresult[1])+","+str(med_norm_ratio)+","+ \                       str(med_norm_ratios_wt_abund)+","+str(avg_norm_ratio)+"\n")                FILE.close()                        # Create the scatter plot with all normalization factors             filename = basename[0]+"_norm_factors"            saveplot_ratios_w_regs(norm_light_abund[:],norm_heavy_abund[:],filename,ktdata[0],ktdata[1],regresult[0],regresult[1],med_norm_ratio,med_norm_ratios_wt_abund,8)        else:             print "No peaks found"        print "Normalization Complete"        print    else:        print "skipping normalization"        ktdata = []        ktdata.append(float(norm_file_factors[4]))        print "Using KT Norm Factor from file = ", ktdata    print "Calculating Peptide Ratios ..."###################################################   Calculate the peptide ratio for target mass  ###################################################    for m in range(0,len(options.target_mass)):        target_mass=options.target_mass[m]                label = options.label_mass * options.num_labels[m]            print        print " - Scanning Target Mass = " + str(target_mass) + ": Label Mass = " + str(label)        # Create list        peaks = []        mass = []        abund = []        test_abund = []        rtime = []        scan_num = []        num_peaks = []        results = []        # Read in scans and parse data        i=0        j=0        total_abund=[0.0,0.0]            a = AutoVivification()          peak_flag = 0                for i in range (0,len(all_norm_light_masses)):#           Untested but would address an issue where the data file ends with the last peak#            if i == len(norm_light_masses):#                peak_flag = 1            if peak_flag and (all_norm_retention[i] > (last_ret_time + rettime_tol * 60)):                if len(light_abund) < 3:                    print " ----- Warning: Peptide detected but fewer than 3 data points.  Try lowering the threshold"                                    else:                    # Calculate the SILAC ratio for the target peptide by linear regression, robust linear regression and median                    lrresult = linreg(light_abund[:],heavy_abund[:])                    ktresult = ktrreg (light_abund[:],heavy_abund[:])                    medratio = listmed (light_abund[:],heavy_abund[:])                    # Output the peak information of each matched pair into a spreadsheet,                     # including retention time, charge, isotope, label number, light mass, light abundance, heavy mass and heavy abundance                    filename = basename[0]+"_target-"+ str(target_mass)+"_label-"+ \                               str(label)+"_"+str(start_ret_time)+"s-"+\                               str(last_ret_time)+"s_data.csv"                                                  max_abund = max(light_abund+heavy_abund)                                        c_one= []  # number of singly charged peaks                    c_two = [] # number of doubly charged peaks                    c_three = []  # number of triply charged peaks                    c_four = []   # number of quadrupoly charged peaks                    iso_zero= []  # number of monoisotopic peak                    iso_one = []  # number of first isotopic peaks                    iso_two = []  # number of second isotopic peaks                    iso_three= [] # number of third isotopic peaks                    iso_four=[]   # number of fourth isotopic peaks                    FILE = open(filename,'w')                    FILE.write("Retention Time, Charge, Isotope, Is Labeled, Light Mass, Light abundance, Heavy Mass, Heavy Abunsdance" +"\n")                    for i in range(0, len(light_abund)):                        if c_val[i]==1:                            c_one.append(c_val[i])                        if c_val[i]==2:                            c_two.append(c_val[i])                        if c_val[i]==3:                            c_three.append(c_val[i])                        if c_val[i]==4:                            c_four.append(c_val[i])                                                   if iso_val[i]==0:                            iso_zero.append(iso_val[i])                        if iso_val[i]==1:                            iso_one.append(iso_val[i])                        if iso_val[i]==2:                            iso_two.append(iso_val[i])                        if iso_val[i]==3:                            iso_three.append(iso_val[i])                        if iso_val[i]==4:                            iso_four.append(iso_val[i])                                                FILE.write(str(ret_val[i])+", "+ str(c_val[i])+", "+ str(iso_val[i])+", "+ \                                   str(label_val[i])+", " + str(light_masses[i])+", "+ \                                   str(light_abund[i])+", "+ str(heavy_masses[i])+", "+ \                                   str(heavy_abund[i])+ "\n")                    FILE.close()                                        # Output the normalized peptide ratios into a spreadsheet                    filename = basename[0]+"_target-"+str(target_mass)+"_label-"+\                               str(label)+"_"+str(start_ret_time)+"s-"+\                               str(last_ret_time)+"s_peptide_ratio_results.csv"                    FILE = open(filename,'w')                                       FILE.write("file, peptide sequence,mass, label, start_ret_time, last_ret_time,N,max abundance, RLR Slope,RLR Slope StdDev, RLR Intercept,RLR Intercept StdDev, LR Slope, LR Slope StdDev,LR Intercept, LR Intercept StDev, median ratio, RLR Ratio (rlr norm), LR Ratio (rlr norm), # of +1, # of +2, # of +3, # of +4, # of monoiso, # of di-iso, # of tri-iso, # of tetra-iso, # of penta-iso"+"\n")                    FILE.write(basename[0]+","+  peptide_seq + "," +str(target_mass)+"," + \                               str(label)+"," + str(start_ret_time)+","+\                               str(last_ret_time)+"," + str(len(light_abund))+","+ str(max_abund) + "," +str(ktresult[0])+","+str(ktresult[3])+","+str(ktresult[1])+","+\                               str(ktresult[4])+","+str(lrresult[0])+","+str(lrresult[4])+","+\                               str(lrresult[1])+","+str(lrresult[5]) +"," + str(medratio)+","+\                               str(ktresult[0]/ktdata[0])+","+str(lrresult[0]/ktdata[0])+", " + str(len(c_one))+", "+ str(len(c_two))+", "+ \                               str(len(c_three))+", " + str(len(c_four))+", "+ str(len(iso_zero)) +", "+ str(len(iso_one)) +", "+ str(len(iso_two))+", " + \                               str(len(iso_three)) +", "+ str(len(iso_four)) + "\n")                    FILE.close()                                        # Plot the scatter plot of all the heavy and light abundance pairs for the target peptide with the ratios calculated by robust linear regression and linear regression                    saveplot_ratios_w_regs(light_abund[:],heavy_abund[:],filename,ktresult[0],ktresult[1],lrresult[0],lrresult[1],size=12)                                  total_abund[0] = 0                total_abund[1] = 0                peak_flag = 0             else:                # Find the matched pair of the target peptide                    for c in range(1,maxcharge+1):                         for iso in range(0,maxiso+1):                          tmp_ratio = [0,0]                        for l in range(0,2):                                                                 if math.fabs(all_norm_light_masses[i] - (target_mass + (iso*C13Shift) + (proton * c-1)) / c) < tol and \                                math.fabs(all_norm_heavy_masses[i] - (target_mass + (iso*C13Shift) + (l*label)+ (proton * c-1)) / c) < tol:                                                   if peak_flag == 0:                                    if DEBUG:                                        print " --- Peak detected at " + str(all_norm_retention[i])                                        print "Start of Peak detected"                                        print "-"*100                                        print '{0:6} {1:1} {2:1} {3:1} {4:10} {5:10} {6:10} {7:10} {8:10} {9:10} '.format(\                                                "RT","c","i","l","light target","heavy target","light mass","l0 abund","heavy mass","l1 abund")                                                                        start_ret_time = all_norm_retention[i]                                    ret_val =[]                                    c_val = []                                    iso_val = []                                    label_val = []                                    light_masses = []                                    heavy_masses = []                                    light_abund = []                                    heavy_abund = []                                                                                                                last_ret_time = all_norm_retention[i]                                peak_flag = 1                                                          if DEBUG:                                    print all_norm_retention[i], c, iso, l,(target_mass + (iso*C13Shift) + (proton * c-1)) / c,\                                         (target_mass + (iso*C13Shift) + (l*label) + (proton * c-1)) / c, all_norm_light_masses[i], \                                          all_norm_light_abund[i], all_norm_heavy_masses[i], all_norm_heavy_abund[i]                                                                   ret_val.append(all_norm_retention[i])                                         c_val.append(c)                                                               iso_val.append(iso)                                                           label_val.append(l)                                                           light_masses.append(all_norm_light_masses[i])                                 light_abund.append(all_norm_light_abund[i])                                   heavy_masses.append(all_norm_heavy_masses[i])                                 heavy_abund.append(all_norm_heavy_abund[i])                  print "\nFinished Analysis of " + str(data_file)class AutoVivification(dict):    """Implementation of perl's autovivification feature."""    def __getitem__(self, item):        try:            return dict.__getitem__(self, item)        except KeyError:            value = self[item] = type(self)()            return value             if __name__ == "__main__":    main();